# -*- coding: utf-8 -*-
"""abi276_Hands_on10_Unsupervised_ML_anomaly_detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bGDf_oSRKmnUMNlYUIrnGFdEnal1_LwM

# Hands_on 8: Anomaly Detection on Financial Data using Unsupervised ML

*Note: This session is graded (binary grading "Complete/Incomplete"). Complete all the exercises and submit the ipynb to canvas under assignment Hands-on8: Anomaly Detection

Turn in Hands_on8 exercises by **Friday (tomorrow) (03/09), 11:59 PM**

**Important Notes:**

**Group Representatives: Fill out the group information form here: https://forms.gle/iQ49EjDsZdjAouYh6 **

**Also, please fill out this mid-course survey to help me prepare better : https://forms.gle/DbmNTiQd7CPU1c4k6 **

## 0. Financial Data Analysis using Yahoo Finance API
Take a look at the Yahoo Finance API here: https://pypi.org/project/yfinance/

This API allows us to download and analysis financial data for companies.

We will download data for a company (say, google or code name GOOG) for a 1-year period and see if there is any anomaly.

## 1. Downloading and analyzing data for Google

We will download data for a company (say, google or code name GOOG) for a 1-year period and see if there is any anomaly.
"""

try:
    import yfinance
except:
    import sys
    !pip install yfinance
    import yfinance

start_date = '2022-10-25'
end_date = '2023-10-25'

data_df = yfinance.download('GOOG', start_date, end_date)

# Print a few lines
data_df.head()

data_df.info()

# Now let's plot some of these columns as a line graph

from matplotlib import pyplot

pyplot.plot(data_df["High"])

# Separately plot another column
# NOTE: Always plot separately in different blocks to avoid superposition

pyplot.plot(data_df["Volume"])

"""As it appears, `volume` is a variable that has many anomalies (too high and too low values). Can we detect the anomalies automatically?

## 2. Analyzing Volume

According to investopedia (https://www.investopedia.com/terms/v/volume.asp),

*"Volume is the amount of an asset or security that changes hands over some period of time, often over the course of a day. For instance, stock trading volume would refer to the number of shares of a security traded between its daily open and close. Trading volume, and changes to volume over the course of time, are important inputs for technical traders."*

A simple google search also yields, "volume of a stock is the number of shares traded in a given period". Traders and investors use the metric to gauge the interest in a security to help them make trading decisions."

Letâ€™s just start by detecting violations of seasonal patterns by anomalies and volume variable.

Now, there are many nice algorithms and libraries available for anomaly detection in univariate and multi-variate settings. We just define a simple algorithm based on Clustering.

**What is our algorithm?**
- Try to learn two clusters from just volume data. Hope that these two clusters contain lower and higher values respectively**
- See which points are too far from any of these clusters and label them as anomalous points.**
"""

from sklearn.cluster import KMeans
kmeans_model = KMeans(n_clusters=2, random_state=0, n_init=1)
kmeans_model.fit(data_df[["Volume"]].to_numpy())

center = kmeans_model.cluster_centers_

print(center)

"""###  3. Detecting Anomalous Points"""

# we are trying to find out indices of volume values that are too far from either of the centers
from math import sqrt

index = 0
distance_data = {}

for volume in data_df["Volume"]:
    distance1 = sqrt((volume - center[0])**2)
    distance2 = sqrt((volume - center[1])**2)
    sum_distance = distance1+distance2
    distance_data[index] = sum_distance
    index=index+1

# Sort the dictionary by value
top_5_X = []
top_5_Y = []

for point in sorted(distance_data,key=distance_data.get,reverse=True):
    top_5_X.append(point)
    top_5_Y.append(data_df["Volume"][point])

#Take the top 5 values as anomalous and plot them

# First plot the original data
pyplot.plot(range(len(data_df["Volume"])), data_df["Volume"])

# Then add a layer scatter plotting the anomalous points
pyplot.scatter(top_5_X[:5],top_5_Y[:5],color="maroon")

"""**Comments**

We can see that some of the anomalous points can be found out using clustering and computing distance from the center of the cluster. May be anomalies are related to seasons.

We can extend this to multi-variate anomaly detection where we are trying to detect anomalies in data-points that have many attributes (features) considered together. In such cases, we can go for K-means clustering and Distance Computation using Euclidean Distance.

## Exercise E1. Boeing Data Analysis

In a brand new Jupyter notebook, repeat the same exercise for **Boeing** (Code "BA"), or free free to go for a company of your choice. What kind of trends do you see. Could you detect anomalous points in volume variable? Explain your findings in a markdown block.

**Offline-** Try to repeat the exercise by setting K=5 in K-means clustering. Does that make a difference?
"""

#get fiancal data from boeing
import yfinance
#create a dataframe of finacial data
start_date = '2022-10-25'
end_date = '2023-10-25'
data_df = yfinance.download('BA', start_date, end_date)

#look at patterns and trends
from matplotlib import pyplot
pyplot.plot(data_df["High"], "green")
pyplot.plot(data_df["Low"], "red")
pyplot.title("Highs and Lows of Boeing Stock from Nov. 2022-23 (Green=High; Red=Low)")
pyplot.xlabel("Dates")
pyplot.ylabel("Value per Stock")

pyplot.plot(data_df["Open"], "blue")
pyplot.plot(data_df["Close"], "orange")
pyplot.title("Opens and Closes of Boeing Stock from Nov. 2022-23 (Blue=Opens; Orange=Close)")
pyplot.xlabel("Dates")
pyplot.ylabel("Value per Stock")

"""The open, close, high, and low value of the stock all follow roughly the same trend of each other.


There was a trend of large increase from 22-11 to 23-01

There was a trend of slight increase from 23-01 to 23-07

There was a trend of large increase from 23-08 to 23-09

There was a trend of large decrease from 23-09 to 23-11
"""

#create cluster centers for volume
from sklearn.cluster import KMeans
kmeans_model = KMeans(n_clusters=2, random_state=0, n_init=1)
kmeans_model.fit(data_df[["Volume"]].to_numpy())
center = kmeans_model.cluster_centers_
#find anomalies
from math import sqrt
index = 0
distance_data = {}
for volume in data_df["Volume"]:
    distance1 = sqrt((volume - center[0])**2)
    distance2 = sqrt((volume - center[1])**2)
    sum_distance = distance1+distance2
    distance_data[index] = sum_distance
    index=index+1
# Sort the dictionary by value
top_5_X = []
top_5_Y = []
for point in sorted(distance_data,key=distance_data.get,reverse=True):
    top_5_X.append(point)
    top_5_Y.append(data_df["Volume"][point])
#Take the top 5 values as anomalous and plot them
#create a plot of volume
pyplot.plot(range(len(data_df["Volume"])), data_df["Volume"])
pyplot.title("Volume of Boeing Stock from Nov. 2022-23")
pyplot.xlabel("Days")
pyplot.ylabel("Volume by 10,000,000")
# Then add a layer scatter plotting the anomalous points
pyplot.scatter(top_5_X[:5],top_5_Y[:5],color="maroon")
  #explain findings

"""We can see some anomals in the volume using cluster; most of the anomals occur near the closing or opening of an economic quarter.

This shows that trading in Boeing is fairly consistent with small and short lasting changes occuring when earnings reports (and other documents related to ending/opening of a quarter) come out.
"""